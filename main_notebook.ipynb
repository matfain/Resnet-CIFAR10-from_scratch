{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main project notebook  \n",
    "This notebook uses the other modules in the repository in order to train from scratch 3 different Resnets and compare their performance.  \n",
    "It's important to note that the final accuracy results is affected by the different hyperparameters used in the training process, so it's possible to obtain better results by improving them, this are simply the ones i found to work best for me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing relevant libraries and files\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from math import floor\n",
    "from Resnet_18_34 import *\n",
    "from Resnet_50 import *\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' #checking for gpu availability\n",
    "dtype = torch.float32\n",
    "print_every = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#Loading and preprocssing the CIFAR-10 Dataset\n",
    "data_root = r'C:\\Users\\matan\\Desktop\\MLDL_Projects\\Resnet\\Cifar-10'\n",
    "NUM_TRAIN = 49000\n",
    "\n",
    "transform = T.Compose([\n",
    "                T.ToTensor(),\n",
    "                T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "            ])\n",
    "\n",
    "cifar10_train = dset.CIFAR10(root=data_root, train=True, download=True,\n",
    "                             transform=transform)\n",
    "loader_train = DataLoader(cifar10_train, batch_size=64,\n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "cifar10_val = dset.CIFAR10(root=data_root, train=True, download=True,\n",
    "                           transform=transform)\n",
    "loader_val = DataLoader(cifar10_val, batch_size=64,\n",
    "                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n",
    "\n",
    "cifar10_test = dset.CIFAR10(root=data_root, train=False, download=True,\n",
    "                            transform=transform)\n",
    "loader_test = DataLoader(cifar10_test, batch_size=64)\n",
    "\n",
    "labels_dic = {0:\"airplane\", 1:\"automobile\", 2:\"bird\", 3:\"cat\", 4:\"deer\", 5:\"dog\", 6:\"frog\", 7:\"horse\", 8:\"ship\", 9:\"truck\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining functions that will be used for training the model\n",
    "def check_accuracy(loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        return acc\n",
    "    \n",
    "def training_loop(model, optimizer, epochs=1, decay= False):\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    step = 0\n",
    "    for e in range(epochs):\n",
    "        print(f\"Starting epoch {e + 1}\")\n",
    "\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()                         # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)                     #scores are the logits which are the output of the model\n",
    "            loss = F.cross_entropy(scores, y)     #This applies softmax on the logits as well as cross entropy loss function\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "            val_acc = check_accuracy(loader_val, model)\n",
    "            # Writing to tensorboard \n",
    "            writer.add_scalar('Training loss', loss, global_step= step)\n",
    "            writer.add_scalar('Validation Accuracy', val_acc , global_step= step)\n",
    "            step += 1\n",
    "\n",
    "            if t % print_every == 0:\n",
    "                print(f'Iteration {t}, training loss = {loss.item():.4f}')\n",
    "                print(f'Validation set accuracy is : {100*val_acc:.2f}%')\n",
    "                print()\n",
    "\n",
    "        if decay==True:\n",
    "          scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resnet18 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           4,864\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "            Layer0-3           [-1, 64, 32, 32]               0\n",
      "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
      "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
      "            Conv2d-6           [-1, 64, 32, 32]          36,928\n",
      "       BatchNorm2d-7           [-1, 64, 32, 32]             128\n",
      "          ResBlock-8           [-1, 64, 32, 32]               0\n",
      "            Conv2d-9           [-1, 64, 32, 32]          36,928\n",
      "      BatchNorm2d-10           [-1, 64, 32, 32]             128\n",
      "           Conv2d-11           [-1, 64, 32, 32]          36,928\n",
      "      BatchNorm2d-12           [-1, 64, 32, 32]             128\n",
      "         ResBlock-13           [-1, 64, 32, 32]               0\n",
      "           Conv2d-14          [-1, 128, 16, 16]           8,320\n",
      "      BatchNorm2d-15          [-1, 128, 16, 16]             256\n",
      "           Conv2d-16          [-1, 128, 16, 16]          73,856\n",
      "      BatchNorm2d-17          [-1, 128, 16, 16]             256\n",
      "           Conv2d-18          [-1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-19          [-1, 128, 16, 16]             256\n",
      "         ResBlock-20          [-1, 128, 16, 16]               0\n",
      "           Conv2d-21          [-1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-22          [-1, 128, 16, 16]             256\n",
      "           Conv2d-23          [-1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-24          [-1, 128, 16, 16]             256\n",
      "         ResBlock-25          [-1, 128, 16, 16]               0\n",
      "           Conv2d-26            [-1, 256, 8, 8]          33,024\n",
      "      BatchNorm2d-27            [-1, 256, 8, 8]             512\n",
      "           Conv2d-28            [-1, 256, 8, 8]         295,168\n",
      "      BatchNorm2d-29            [-1, 256, 8, 8]             512\n",
      "           Conv2d-30            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-31            [-1, 256, 8, 8]             512\n",
      "         ResBlock-32            [-1, 256, 8, 8]               0\n",
      "           Conv2d-33            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-34            [-1, 256, 8, 8]             512\n",
      "           Conv2d-35            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-36            [-1, 256, 8, 8]             512\n",
      "         ResBlock-37            [-1, 256, 8, 8]               0\n",
      "           Conv2d-38            [-1, 512, 4, 4]         131,584\n",
      "      BatchNorm2d-39            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-40            [-1, 512, 4, 4]       1,180,160\n",
      "      BatchNorm2d-41            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-42            [-1, 512, 4, 4]       2,359,808\n",
      "      BatchNorm2d-43            [-1, 512, 4, 4]           1,024\n",
      "         ResBlock-44            [-1, 512, 4, 4]               0\n",
      "           Conv2d-45            [-1, 512, 4, 4]       2,359,808\n",
      "      BatchNorm2d-46            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-47            [-1, 512, 4, 4]       2,359,808\n",
      "      BatchNorm2d-48            [-1, 512, 4, 4]           1,024\n",
      "         ResBlock-49            [-1, 512, 4, 4]               0\n",
      "AdaptiveAvgPool2d-50            [-1, 512, 1, 1]               0\n",
      "           Linear-51                   [-1, 10]           5,130\n",
      "      Final_layer-52                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 11,181,834\n",
      "Trainable params: 11,181,834\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 11.75\n",
      "Params size (MB): 42.66\n",
      "Estimated Total Size (MB): 54.42\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Initializing model and viewing architecture\n",
    "model_18 = ResNet18(in_channels= 3, layer0=Layer0, resblock=ResBlock, final_layer=Final_layer, num_classes= 10).to(device)\n",
    "summary(model_18, input_size= (3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "Iteration 0, training loss = 2.3391\n",
      "Validation set accuracy is : 9.80%\n",
      "\n",
      "Iteration 100, training loss = 1.7083\n",
      "Validation set accuracy is : 39.80%\n",
      "\n",
      "Iteration 200, training loss = 1.4068\n",
      "Validation set accuracy is : 47.70%\n",
      "\n",
      "Iteration 300, training loss = 1.3830\n",
      "Validation set accuracy is : 47.90%\n",
      "\n",
      "Iteration 400, training loss = 1.3576\n",
      "Validation set accuracy is : 42.50%\n",
      "\n",
      "Iteration 500, training loss = 1.0302\n",
      "Validation set accuracy is : 58.60%\n",
      "\n",
      "Iteration 600, training loss = 1.1637\n",
      "Validation set accuracy is : 63.50%\n",
      "\n",
      "Iteration 700, training loss = 0.9105\n",
      "Validation set accuracy is : 63.10%\n",
      "\n",
      "Starting epoch 2\n",
      "Iteration 0, training loss = 1.1451\n",
      "Validation set accuracy is : 60.20%\n",
      "\n",
      "Iteration 100, training loss = 1.0219\n",
      "Validation set accuracy is : 67.30%\n",
      "\n",
      "Iteration 200, training loss = 1.0713\n",
      "Validation set accuracy is : 71.40%\n",
      "\n",
      "Iteration 300, training loss = 0.8833\n",
      "Validation set accuracy is : 65.90%\n",
      "\n",
      "Iteration 400, training loss = 0.6891\n",
      "Validation set accuracy is : 65.30%\n",
      "\n",
      "Iteration 500, training loss = 0.5356\n",
      "Validation set accuracy is : 69.70%\n",
      "\n",
      "Iteration 600, training loss = 0.6388\n",
      "Validation set accuracy is : 69.50%\n",
      "\n",
      "Iteration 700, training loss = 0.6406\n",
      "Validation set accuracy is : 72.40%\n",
      "\n",
      "Starting epoch 3\n",
      "Iteration 0, training loss = 0.5379\n",
      "Validation set accuracy is : 69.70%\n",
      "\n",
      "Iteration 100, training loss = 0.4903\n",
      "Validation set accuracy is : 75.10%\n",
      "\n",
      "Iteration 200, training loss = 0.5895\n",
      "Validation set accuracy is : 76.40%\n",
      "\n",
      "Iteration 300, training loss = 0.4064\n",
      "Validation set accuracy is : 75.40%\n",
      "\n",
      "Iteration 400, training loss = 0.5225\n",
      "Validation set accuracy is : 79.20%\n",
      "\n",
      "Iteration 500, training loss = 0.8570\n",
      "Validation set accuracy is : 77.50%\n",
      "\n",
      "Iteration 600, training loss = 0.6460\n",
      "Validation set accuracy is : 79.00%\n",
      "\n",
      "Iteration 700, training loss = 0.7395\n",
      "Validation set accuracy is : 77.50%\n",
      "\n",
      "Starting epoch 4\n",
      "Iteration 0, training loss = 0.2292\n",
      "Validation set accuracy is : 80.00%\n",
      "\n",
      "Iteration 100, training loss = 0.3545\n",
      "Validation set accuracy is : 75.80%\n",
      "\n",
      "Iteration 200, training loss = 0.5010\n",
      "Validation set accuracy is : 77.40%\n",
      "\n",
      "Iteration 300, training loss = 0.5566\n",
      "Validation set accuracy is : 81.90%\n",
      "\n",
      "Iteration 400, training loss = 0.4285\n",
      "Validation set accuracy is : 78.90%\n",
      "\n",
      "Iteration 500, training loss = 0.4349\n",
      "Validation set accuracy is : 79.50%\n",
      "\n",
      "Iteration 600, training loss = 0.6643\n",
      "Validation set accuracy is : 79.50%\n",
      "\n",
      "Iteration 700, training loss = 0.4293\n",
      "Validation set accuracy is : 81.50%\n",
      "\n",
      "Starting epoch 5\n",
      "Iteration 0, training loss = 0.3361\n",
      "Validation set accuracy is : 79.70%\n",
      "\n",
      "Iteration 100, training loss = 0.2080\n",
      "Validation set accuracy is : 82.90%\n",
      "\n",
      "Iteration 200, training loss = 0.2089\n",
      "Validation set accuracy is : 82.80%\n",
      "\n",
      "Iteration 300, training loss = 0.4083\n",
      "Validation set accuracy is : 83.00%\n",
      "\n",
      "Iteration 400, training loss = 0.3788\n",
      "Validation set accuracy is : 79.90%\n",
      "\n",
      "Iteration 500, training loss = 0.2511\n",
      "Validation set accuracy is : 83.80%\n",
      "\n",
      "Iteration 600, training loss = 0.4097\n",
      "Validation set accuracy is : 81.30%\n",
      "\n",
      "Iteration 700, training loss = 0.2880\n",
      "Validation set accuracy is : 75.90%\n",
      "\n",
      "Starting epoch 6\n",
      "Iteration 0, training loss = 0.3612\n",
      "Validation set accuracy is : 80.50%\n",
      "\n",
      "Iteration 100, training loss = 0.2736\n",
      "Validation set accuracy is : 81.40%\n",
      "\n",
      "Iteration 200, training loss = 0.1590\n",
      "Validation set accuracy is : 82.40%\n",
      "\n",
      "Iteration 300, training loss = 0.2863\n",
      "Validation set accuracy is : 83.40%\n",
      "\n",
      "Iteration 400, training loss = 0.1929\n",
      "Validation set accuracy is : 82.60%\n",
      "\n",
      "Iteration 500, training loss = 0.2217\n",
      "Validation set accuracy is : 80.30%\n",
      "\n",
      "Iteration 600, training loss = 0.3663\n",
      "Validation set accuracy is : 81.30%\n",
      "\n",
      "Iteration 700, training loss = 0.2252\n",
      "Validation set accuracy is : 82.90%\n",
      "\n",
      "Starting epoch 7\n",
      "Iteration 0, training loss = 0.1896\n",
      "Validation set accuracy is : 83.10%\n",
      "\n",
      "Iteration 100, training loss = 0.1326\n",
      "Validation set accuracy is : 83.90%\n",
      "\n",
      "Iteration 200, training loss = 0.1327\n",
      "Validation set accuracy is : 82.90%\n",
      "\n",
      "Iteration 300, training loss = 0.1424\n",
      "Validation set accuracy is : 79.60%\n",
      "\n",
      "Iteration 400, training loss = 0.1371\n",
      "Validation set accuracy is : 84.50%\n",
      "\n",
      "Iteration 500, training loss = 0.1437\n",
      "Validation set accuracy is : 81.30%\n",
      "\n",
      "Iteration 600, training loss = 0.1066\n",
      "Validation set accuracy is : 82.20%\n",
      "\n",
      "Iteration 700, training loss = 0.1158\n",
      "Validation set accuracy is : 84.10%\n",
      "\n",
      "Starting epoch 8\n",
      "Iteration 0, training loss = 0.1111\n",
      "Validation set accuracy is : 83.10%\n",
      "\n",
      "Iteration 100, training loss = 0.0247\n",
      "Validation set accuracy is : 85.70%\n",
      "\n",
      "Iteration 200, training loss = 0.0320\n",
      "Validation set accuracy is : 85.80%\n",
      "\n",
      "Iteration 300, training loss = 0.0647\n",
      "Validation set accuracy is : 83.70%\n",
      "\n",
      "Iteration 400, training loss = 0.1023\n",
      "Validation set accuracy is : 84.80%\n",
      "\n",
      "Iteration 500, training loss = 0.1076\n",
      "Validation set accuracy is : 83.90%\n",
      "\n",
      "Iteration 600, training loss = 0.1148\n",
      "Validation set accuracy is : 84.40%\n",
      "\n",
      "Iteration 700, training loss = 0.1324\n",
      "Validation set accuracy is : 83.40%\n",
      "\n",
      "Starting epoch 9\n",
      "Iteration 0, training loss = 0.0398\n",
      "Validation set accuracy is : 81.50%\n",
      "\n",
      "Iteration 100, training loss = 0.0369\n",
      "Validation set accuracy is : 84.10%\n",
      "\n",
      "Iteration 200, training loss = 0.0288\n",
      "Validation set accuracy is : 84.40%\n",
      "\n",
      "Iteration 300, training loss = 0.1031\n",
      "Validation set accuracy is : 85.40%\n",
      "\n",
      "Iteration 400, training loss = 0.0884\n",
      "Validation set accuracy is : 84.40%\n",
      "\n",
      "Iteration 500, training loss = 0.0499\n",
      "Validation set accuracy is : 84.10%\n",
      "\n",
      "Iteration 600, training loss = 0.0265\n",
      "Validation set accuracy is : 85.20%\n",
      "\n",
      "Iteration 700, training loss = 0.0589\n",
      "Validation set accuracy is : 83.90%\n",
      "\n",
      "Starting epoch 10\n",
      "Iteration 0, training loss = 0.0227\n",
      "Validation set accuracy is : 84.30%\n",
      "\n",
      "Iteration 100, training loss = 0.0098\n",
      "Validation set accuracy is : 84.70%\n",
      "\n",
      "Iteration 200, training loss = 0.0235\n",
      "Validation set accuracy is : 84.30%\n",
      "\n",
      "Iteration 300, training loss = 0.0159\n",
      "Validation set accuracy is : 84.30%\n",
      "\n",
      "Iteration 400, training loss = 0.0184\n",
      "Validation set accuracy is : 84.30%\n",
      "\n",
      "Iteration 500, training loss = 0.0301\n",
      "Validation set accuracy is : 85.10%\n",
      "\n",
      "Iteration 600, training loss = 0.0383\n",
      "Validation set accuracy is : 82.50%\n",
      "\n",
      "Iteration 700, training loss = 0.0556\n",
      "Validation set accuracy is : 84.70%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(f'TB/model_18')\n",
    "optimizer = optim.Adam(model_18.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.85)  # lr decay every epoch\n",
    "\n",
    "training_loop(model_18, optimizer, epochs=10, decay=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resnet34 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           4,864\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "            Layer0-3           [-1, 64, 32, 32]               0\n",
      "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
      "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
      "            Conv2d-6           [-1, 64, 32, 32]          36,928\n",
      "       BatchNorm2d-7           [-1, 64, 32, 32]             128\n",
      "          ResBlock-8           [-1, 64, 32, 32]               0\n",
      "            Conv2d-9           [-1, 64, 32, 32]          36,928\n",
      "      BatchNorm2d-10           [-1, 64, 32, 32]             128\n",
      "           Conv2d-11           [-1, 64, 32, 32]          36,928\n",
      "      BatchNorm2d-12           [-1, 64, 32, 32]             128\n",
      "         ResBlock-13           [-1, 64, 32, 32]               0\n",
      "           Conv2d-14           [-1, 64, 32, 32]          36,928\n",
      "      BatchNorm2d-15           [-1, 64, 32, 32]             128\n",
      "           Conv2d-16           [-1, 64, 32, 32]          36,928\n",
      "      BatchNorm2d-17           [-1, 64, 32, 32]             128\n",
      "         ResBlock-18           [-1, 64, 32, 32]               0\n",
      "           Conv2d-19          [-1, 128, 16, 16]           8,320\n",
      "      BatchNorm2d-20          [-1, 128, 16, 16]             256\n",
      "           Conv2d-21          [-1, 128, 16, 16]          73,856\n",
      "      BatchNorm2d-22          [-1, 128, 16, 16]             256\n",
      "           Conv2d-23          [-1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-24          [-1, 128, 16, 16]             256\n",
      "         ResBlock-25          [-1, 128, 16, 16]               0\n",
      "           Conv2d-26          [-1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-27          [-1, 128, 16, 16]             256\n",
      "           Conv2d-28          [-1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-29          [-1, 128, 16, 16]             256\n",
      "         ResBlock-30          [-1, 128, 16, 16]               0\n",
      "           Conv2d-31          [-1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-32          [-1, 128, 16, 16]             256\n",
      "           Conv2d-33          [-1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-34          [-1, 128, 16, 16]             256\n",
      "         ResBlock-35          [-1, 128, 16, 16]               0\n",
      "           Conv2d-36          [-1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-37          [-1, 128, 16, 16]             256\n",
      "           Conv2d-38          [-1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-39          [-1, 128, 16, 16]             256\n",
      "         ResBlock-40          [-1, 128, 16, 16]               0\n",
      "           Conv2d-41            [-1, 256, 8, 8]          33,024\n",
      "      BatchNorm2d-42            [-1, 256, 8, 8]             512\n",
      "           Conv2d-43            [-1, 256, 8, 8]         295,168\n",
      "      BatchNorm2d-44            [-1, 256, 8, 8]             512\n",
      "           Conv2d-45            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-46            [-1, 256, 8, 8]             512\n",
      "         ResBlock-47            [-1, 256, 8, 8]               0\n",
      "           Conv2d-48            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-49            [-1, 256, 8, 8]             512\n",
      "           Conv2d-50            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-51            [-1, 256, 8, 8]             512\n",
      "         ResBlock-52            [-1, 256, 8, 8]               0\n",
      "           Conv2d-53            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-54            [-1, 256, 8, 8]             512\n",
      "           Conv2d-55            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-56            [-1, 256, 8, 8]             512\n",
      "         ResBlock-57            [-1, 256, 8, 8]               0\n",
      "           Conv2d-58            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-59            [-1, 256, 8, 8]             512\n",
      "           Conv2d-60            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-61            [-1, 256, 8, 8]             512\n",
      "         ResBlock-62            [-1, 256, 8, 8]               0\n",
      "           Conv2d-63            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-64            [-1, 256, 8, 8]             512\n",
      "           Conv2d-65            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-66            [-1, 256, 8, 8]             512\n",
      "         ResBlock-67            [-1, 256, 8, 8]               0\n",
      "           Conv2d-68            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-69            [-1, 256, 8, 8]             512\n",
      "           Conv2d-70            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-71            [-1, 256, 8, 8]             512\n",
      "         ResBlock-72            [-1, 256, 8, 8]               0\n",
      "           Conv2d-73            [-1, 512, 4, 4]         131,584\n",
      "      BatchNorm2d-74            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-75            [-1, 512, 4, 4]       1,180,160\n",
      "      BatchNorm2d-76            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-77            [-1, 512, 4, 4]       2,359,808\n",
      "      BatchNorm2d-78            [-1, 512, 4, 4]           1,024\n",
      "         ResBlock-79            [-1, 512, 4, 4]               0\n",
      "           Conv2d-80            [-1, 512, 4, 4]       2,359,808\n",
      "      BatchNorm2d-81            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-82            [-1, 512, 4, 4]       2,359,808\n",
      "      BatchNorm2d-83            [-1, 512, 4, 4]           1,024\n",
      "         ResBlock-84            [-1, 512, 4, 4]               0\n",
      "           Conv2d-85            [-1, 512, 4, 4]       2,359,808\n",
      "      BatchNorm2d-86            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-87            [-1, 512, 4, 4]       2,359,808\n",
      "      BatchNorm2d-88            [-1, 512, 4, 4]           1,024\n",
      "         ResBlock-89            [-1, 512, 4, 4]               0\n",
      "AdaptiveAvgPool2d-90            [-1, 512, 1, 1]               0\n",
      "           Linear-91                   [-1, 10]           5,130\n",
      "      Final_layer-92                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 21,293,706\n",
      "Trainable params: 21,293,706\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 19.57\n",
      "Params size (MB): 81.23\n",
      "Estimated Total Size (MB): 100.81\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_34 = ResNet34(in_channels= 3, layer0=Layer0, resblock=ResBlock, final_layer=Final_layer, num_classes= 10).to(device)\n",
    "summary(model_34, input_size= (3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "Iteration 0, training loss = 2.5676\n",
      "Validation set accuracy is : 11.20%\n",
      "\n",
      "Iteration 100, training loss = 1.7671\n",
      "Validation set accuracy is : 27.50%\n",
      "\n",
      "Iteration 200, training loss = 1.6446\n",
      "Validation set accuracy is : 45.40%\n",
      "\n",
      "Iteration 300, training loss = 1.5551\n",
      "Validation set accuracy is : 42.90%\n",
      "\n",
      "Iteration 400, training loss = 1.1399\n",
      "Validation set accuracy is : 48.90%\n",
      "\n",
      "Iteration 500, training loss = 1.3526\n",
      "Validation set accuracy is : 53.40%\n",
      "\n",
      "Iteration 600, training loss = 1.0464\n",
      "Validation set accuracy is : 52.30%\n",
      "\n",
      "Iteration 700, training loss = 1.0433\n",
      "Validation set accuracy is : 54.80%\n",
      "\n",
      "Starting epoch 2\n",
      "Iteration 0, training loss = 1.0382\n",
      "Validation set accuracy is : 51.60%\n",
      "\n",
      "Iteration 100, training loss = 1.0513\n",
      "Validation set accuracy is : 62.00%\n",
      "\n",
      "Iteration 200, training loss = 1.1114\n",
      "Validation set accuracy is : 64.90%\n",
      "\n",
      "Iteration 300, training loss = 0.7560\n",
      "Validation set accuracy is : 61.70%\n",
      "\n",
      "Iteration 400, training loss = 0.8832\n",
      "Validation set accuracy is : 65.80%\n",
      "\n",
      "Iteration 500, training loss = 0.9496\n",
      "Validation set accuracy is : 70.30%\n",
      "\n",
      "Iteration 600, training loss = 0.8785\n",
      "Validation set accuracy is : 67.30%\n",
      "\n",
      "Iteration 700, training loss = 1.0061\n",
      "Validation set accuracy is : 70.00%\n",
      "\n",
      "Starting epoch 3\n",
      "Iteration 0, training loss = 0.6096\n",
      "Validation set accuracy is : 71.20%\n",
      "\n",
      "Iteration 100, training loss = 0.6104\n",
      "Validation set accuracy is : 77.30%\n",
      "\n",
      "Iteration 200, training loss = 0.5610\n",
      "Validation set accuracy is : 74.60%\n",
      "\n",
      "Iteration 300, training loss = 0.6815\n",
      "Validation set accuracy is : 75.40%\n",
      "\n",
      "Iteration 400, training loss = 0.7719\n",
      "Validation set accuracy is : 73.40%\n",
      "\n",
      "Iteration 500, training loss = 0.5857\n",
      "Validation set accuracy is : 74.20%\n",
      "\n",
      "Iteration 600, training loss = 0.5556\n",
      "Validation set accuracy is : 67.30%\n",
      "\n",
      "Iteration 700, training loss = 0.5224\n",
      "Validation set accuracy is : 76.40%\n",
      "\n",
      "Starting epoch 4\n",
      "Iteration 0, training loss = 0.6033\n",
      "Validation set accuracy is : 78.00%\n",
      "\n",
      "Iteration 100, training loss = 0.5941\n",
      "Validation set accuracy is : 78.50%\n",
      "\n",
      "Iteration 200, training loss = 0.4638\n",
      "Validation set accuracy is : 80.30%\n",
      "\n",
      "Iteration 300, training loss = 0.3397\n",
      "Validation set accuracy is : 76.20%\n",
      "\n",
      "Iteration 400, training loss = 0.5516\n",
      "Validation set accuracy is : 79.80%\n",
      "\n",
      "Iteration 500, training loss = 0.4367\n",
      "Validation set accuracy is : 78.70%\n",
      "\n",
      "Iteration 600, training loss = 0.7093\n",
      "Validation set accuracy is : 81.10%\n",
      "\n",
      "Iteration 700, training loss = 0.5410\n",
      "Validation set accuracy is : 76.10%\n",
      "\n",
      "Starting epoch 5\n",
      "Iteration 0, training loss = 0.3485\n",
      "Validation set accuracy is : 81.50%\n",
      "\n",
      "Iteration 100, training loss = 0.2379\n",
      "Validation set accuracy is : 82.50%\n",
      "\n",
      "Iteration 200, training loss = 0.5480\n",
      "Validation set accuracy is : 82.10%\n",
      "\n",
      "Iteration 300, training loss = 0.3325\n",
      "Validation set accuracy is : 82.30%\n",
      "\n",
      "Iteration 400, training loss = 0.5234\n",
      "Validation set accuracy is : 82.90%\n",
      "\n",
      "Iteration 500, training loss = 0.2454\n",
      "Validation set accuracy is : 84.10%\n",
      "\n",
      "Iteration 600, training loss = 0.3846\n",
      "Validation set accuracy is : 80.60%\n",
      "\n",
      "Iteration 700, training loss = 0.3673\n",
      "Validation set accuracy is : 80.00%\n",
      "\n",
      "Starting epoch 6\n",
      "Iteration 0, training loss = 0.3822\n",
      "Validation set accuracy is : 80.30%\n",
      "\n",
      "Iteration 100, training loss = 0.3280\n",
      "Validation set accuracy is : 84.20%\n",
      "\n",
      "Iteration 200, training loss = 0.1608\n",
      "Validation set accuracy is : 83.70%\n",
      "\n",
      "Iteration 300, training loss = 0.1981\n",
      "Validation set accuracy is : 83.70%\n",
      "\n",
      "Iteration 400, training loss = 0.3250\n",
      "Validation set accuracy is : 83.60%\n",
      "\n",
      "Iteration 500, training loss = 0.2973\n",
      "Validation set accuracy is : 83.60%\n",
      "\n",
      "Iteration 600, training loss = 0.5345\n",
      "Validation set accuracy is : 81.20%\n",
      "\n",
      "Iteration 700, training loss = 0.2558\n",
      "Validation set accuracy is : 84.70%\n",
      "\n",
      "Starting epoch 7\n",
      "Iteration 0, training loss = 0.2700\n",
      "Validation set accuracy is : 80.90%\n",
      "\n",
      "Iteration 100, training loss = 0.1030\n",
      "Validation set accuracy is : 84.30%\n",
      "\n",
      "Iteration 200, training loss = 0.1516\n",
      "Validation set accuracy is : 80.40%\n",
      "\n",
      "Iteration 300, training loss = 0.2060\n",
      "Validation set accuracy is : 85.40%\n",
      "\n",
      "Iteration 400, training loss = 0.2417\n",
      "Validation set accuracy is : 83.60%\n",
      "\n",
      "Iteration 500, training loss = 0.1953\n",
      "Validation set accuracy is : 82.60%\n",
      "\n",
      "Iteration 600, training loss = 0.1695\n",
      "Validation set accuracy is : 83.70%\n",
      "\n",
      "Iteration 700, training loss = 0.0963\n",
      "Validation set accuracy is : 81.00%\n",
      "\n",
      "Starting epoch 8\n",
      "Iteration 0, training loss = 0.1036\n",
      "Validation set accuracy is : 81.80%\n",
      "\n",
      "Iteration 100, training loss = 0.1079\n",
      "Validation set accuracy is : 85.10%\n",
      "\n",
      "Iteration 200, training loss = 0.1394\n",
      "Validation set accuracy is : 82.70%\n",
      "\n",
      "Iteration 300, training loss = 0.0744\n",
      "Validation set accuracy is : 84.30%\n",
      "\n",
      "Iteration 400, training loss = 0.1586\n",
      "Validation set accuracy is : 84.10%\n",
      "\n",
      "Iteration 500, training loss = 0.1081\n",
      "Validation set accuracy is : 83.20%\n",
      "\n",
      "Iteration 600, training loss = 0.0473\n",
      "Validation set accuracy is : 85.80%\n",
      "\n",
      "Iteration 700, training loss = 0.1424\n",
      "Validation set accuracy is : 84.50%\n",
      "\n",
      "Starting epoch 9\n",
      "Iteration 0, training loss = 0.0929\n",
      "Validation set accuracy is : 82.60%\n",
      "\n",
      "Iteration 100, training loss = 0.0368\n",
      "Validation set accuracy is : 85.30%\n",
      "\n",
      "Iteration 200, training loss = 0.0715\n",
      "Validation set accuracy is : 85.10%\n",
      "\n",
      "Iteration 300, training loss = 0.0300\n",
      "Validation set accuracy is : 86.20%\n",
      "\n",
      "Iteration 400, training loss = 0.0836\n",
      "Validation set accuracy is : 84.60%\n",
      "\n",
      "Iteration 500, training loss = 0.0281\n",
      "Validation set accuracy is : 83.90%\n",
      "\n",
      "Iteration 600, training loss = 0.0637\n",
      "Validation set accuracy is : 86.30%\n",
      "\n",
      "Iteration 700, training loss = 0.0629\n",
      "Validation set accuracy is : 85.30%\n",
      "\n",
      "Starting epoch 10\n",
      "Iteration 0, training loss = 0.0281\n",
      "Validation set accuracy is : 83.80%\n",
      "\n",
      "Iteration 100, training loss = 0.0157\n",
      "Validation set accuracy is : 86.70%\n",
      "\n",
      "Iteration 200, training loss = 0.0387\n",
      "Validation set accuracy is : 86.20%\n",
      "\n",
      "Iteration 300, training loss = 0.0145\n",
      "Validation set accuracy is : 83.50%\n",
      "\n",
      "Iteration 400, training loss = 0.0350\n",
      "Validation set accuracy is : 85.40%\n",
      "\n",
      "Iteration 500, training loss = 0.0328\n",
      "Validation set accuracy is : 85.80%\n",
      "\n",
      "Iteration 600, training loss = 0.0908\n",
      "Validation set accuracy is : 84.10%\n",
      "\n",
      "Iteration 700, training loss = 0.0747\n",
      "Validation set accuracy is : 84.60%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(f'TB/model_34')\n",
    "learning_rate = 1e-3\n",
    "optimizer = optim.Adam(model_34.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.85)  # lr decay every epoch\n",
    "\n",
    "training_loop(model_34, optimizer, epochs=10, decay=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resnet50 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           4,864\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "            Layer0-3           [-1, 64, 32, 32]               0\n",
      "            Conv2d-4          [-1, 256, 32, 32]          16,640\n",
      "       BatchNorm2d-5          [-1, 256, 32, 32]             512\n",
      "            Conv2d-6           [-1, 64, 32, 32]           4,160\n",
      "       BatchNorm2d-7           [-1, 64, 32, 32]             128\n",
      "            Conv2d-8           [-1, 64, 32, 32]          36,928\n",
      "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
      "           Conv2d-10          [-1, 256, 32, 32]          16,640\n",
      "      BatchNorm2d-11          [-1, 256, 32, 32]             512\n",
      "  BottleneckBlock-12          [-1, 256, 32, 32]               0\n",
      "           Conv2d-13           [-1, 64, 32, 32]          16,448\n",
      "      BatchNorm2d-14           [-1, 64, 32, 32]             128\n",
      "           Conv2d-15           [-1, 64, 32, 32]          36,928\n",
      "      BatchNorm2d-16           [-1, 64, 32, 32]             128\n",
      "           Conv2d-17          [-1, 256, 32, 32]          16,640\n",
      "      BatchNorm2d-18          [-1, 256, 32, 32]             512\n",
      "  BottleneckBlock-19          [-1, 256, 32, 32]               0\n",
      "           Conv2d-20           [-1, 64, 32, 32]          16,448\n",
      "      BatchNorm2d-21           [-1, 64, 32, 32]             128\n",
      "           Conv2d-22           [-1, 64, 32, 32]          36,928\n",
      "      BatchNorm2d-23           [-1, 64, 32, 32]             128\n",
      "           Conv2d-24          [-1, 256, 32, 32]          16,640\n",
      "      BatchNorm2d-25          [-1, 256, 32, 32]             512\n",
      "  BottleneckBlock-26          [-1, 256, 32, 32]               0\n",
      "           Conv2d-27          [-1, 512, 16, 16]         131,584\n",
      "      BatchNorm2d-28          [-1, 512, 16, 16]           1,024\n",
      "           Conv2d-29          [-1, 128, 32, 32]          32,896\n",
      "      BatchNorm2d-30          [-1, 128, 32, 32]             256\n",
      "           Conv2d-31          [-1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-32          [-1, 128, 16, 16]             256\n",
      "           Conv2d-33          [-1, 512, 16, 16]          66,048\n",
      "      BatchNorm2d-34          [-1, 512, 16, 16]           1,024\n",
      "  BottleneckBlock-35          [-1, 512, 16, 16]               0\n",
      "           Conv2d-36          [-1, 128, 16, 16]          65,664\n",
      "      BatchNorm2d-37          [-1, 128, 16, 16]             256\n",
      "           Conv2d-38          [-1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-39          [-1, 128, 16, 16]             256\n",
      "           Conv2d-40          [-1, 512, 16, 16]          66,048\n",
      "      BatchNorm2d-41          [-1, 512, 16, 16]           1,024\n",
      "  BottleneckBlock-42          [-1, 512, 16, 16]               0\n",
      "           Conv2d-43          [-1, 128, 16, 16]          65,664\n",
      "      BatchNorm2d-44          [-1, 128, 16, 16]             256\n",
      "           Conv2d-45          [-1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-46          [-1, 128, 16, 16]             256\n",
      "           Conv2d-47          [-1, 512, 16, 16]          66,048\n",
      "      BatchNorm2d-48          [-1, 512, 16, 16]           1,024\n",
      "  BottleneckBlock-49          [-1, 512, 16, 16]               0\n",
      "           Conv2d-50          [-1, 128, 16, 16]          65,664\n",
      "      BatchNorm2d-51          [-1, 128, 16, 16]             256\n",
      "           Conv2d-52          [-1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-53          [-1, 128, 16, 16]             256\n",
      "           Conv2d-54          [-1, 512, 16, 16]          66,048\n",
      "      BatchNorm2d-55          [-1, 512, 16, 16]           1,024\n",
      "  BottleneckBlock-56          [-1, 512, 16, 16]               0\n",
      "           Conv2d-57           [-1, 1024, 8, 8]         525,312\n",
      "      BatchNorm2d-58           [-1, 1024, 8, 8]           2,048\n",
      "           Conv2d-59          [-1, 256, 16, 16]         131,328\n",
      "      BatchNorm2d-60          [-1, 256, 16, 16]             512\n",
      "           Conv2d-61            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-62            [-1, 256, 8, 8]             512\n",
      "           Conv2d-63           [-1, 1024, 8, 8]         263,168\n",
      "      BatchNorm2d-64           [-1, 1024, 8, 8]           2,048\n",
      "  BottleneckBlock-65           [-1, 1024, 8, 8]               0\n",
      "           Conv2d-66            [-1, 256, 8, 8]         262,400\n",
      "      BatchNorm2d-67            [-1, 256, 8, 8]             512\n",
      "           Conv2d-68            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-69            [-1, 256, 8, 8]             512\n",
      "           Conv2d-70           [-1, 1024, 8, 8]         263,168\n",
      "      BatchNorm2d-71           [-1, 1024, 8, 8]           2,048\n",
      "  BottleneckBlock-72           [-1, 1024, 8, 8]               0\n",
      "           Conv2d-73            [-1, 256, 8, 8]         262,400\n",
      "      BatchNorm2d-74            [-1, 256, 8, 8]             512\n",
      "           Conv2d-75            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-76            [-1, 256, 8, 8]             512\n",
      "           Conv2d-77           [-1, 1024, 8, 8]         263,168\n",
      "      BatchNorm2d-78           [-1, 1024, 8, 8]           2,048\n",
      "  BottleneckBlock-79           [-1, 1024, 8, 8]               0\n",
      "           Conv2d-80            [-1, 256, 8, 8]         262,400\n",
      "      BatchNorm2d-81            [-1, 256, 8, 8]             512\n",
      "           Conv2d-82            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-83            [-1, 256, 8, 8]             512\n",
      "           Conv2d-84           [-1, 1024, 8, 8]         263,168\n",
      "      BatchNorm2d-85           [-1, 1024, 8, 8]           2,048\n",
      "  BottleneckBlock-86           [-1, 1024, 8, 8]               0\n",
      "           Conv2d-87            [-1, 256, 8, 8]         262,400\n",
      "      BatchNorm2d-88            [-1, 256, 8, 8]             512\n",
      "           Conv2d-89            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-90            [-1, 256, 8, 8]             512\n",
      "           Conv2d-91           [-1, 1024, 8, 8]         263,168\n",
      "      BatchNorm2d-92           [-1, 1024, 8, 8]           2,048\n",
      "  BottleneckBlock-93           [-1, 1024, 8, 8]               0\n",
      "           Conv2d-94            [-1, 256, 8, 8]         262,400\n",
      "      BatchNorm2d-95            [-1, 256, 8, 8]             512\n",
      "           Conv2d-96            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-97            [-1, 256, 8, 8]             512\n",
      "           Conv2d-98           [-1, 1024, 8, 8]         263,168\n",
      "      BatchNorm2d-99           [-1, 1024, 8, 8]           2,048\n",
      " BottleneckBlock-100           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-101           [-1, 2048, 4, 4]       2,099,200\n",
      "     BatchNorm2d-102           [-1, 2048, 4, 4]           4,096\n",
      "          Conv2d-103            [-1, 512, 8, 8]         524,800\n",
      "     BatchNorm2d-104            [-1, 512, 8, 8]           1,024\n",
      "          Conv2d-105            [-1, 512, 4, 4]       2,359,808\n",
      "     BatchNorm2d-106            [-1, 512, 4, 4]           1,024\n",
      "          Conv2d-107           [-1, 2048, 4, 4]       1,050,624\n",
      "     BatchNorm2d-108           [-1, 2048, 4, 4]           4,096\n",
      " BottleneckBlock-109           [-1, 2048, 4, 4]               0\n",
      "          Conv2d-110            [-1, 512, 4, 4]       1,049,088\n",
      "     BatchNorm2d-111            [-1, 512, 4, 4]           1,024\n",
      "          Conv2d-112            [-1, 512, 4, 4]       2,359,808\n",
      "     BatchNorm2d-113            [-1, 512, 4, 4]           1,024\n",
      "          Conv2d-114           [-1, 2048, 4, 4]       1,050,624\n",
      "     BatchNorm2d-115           [-1, 2048, 4, 4]           4,096\n",
      " BottleneckBlock-116           [-1, 2048, 4, 4]               0\n",
      "          Conv2d-117            [-1, 512, 4, 4]       1,049,088\n",
      "     BatchNorm2d-118            [-1, 512, 4, 4]           1,024\n",
      "          Conv2d-119            [-1, 512, 4, 4]       2,359,808\n",
      "     BatchNorm2d-120            [-1, 512, 4, 4]           1,024\n",
      "          Conv2d-121           [-1, 2048, 4, 4]       1,050,624\n",
      "     BatchNorm2d-122           [-1, 2048, 4, 4]           4,096\n",
      " BottleneckBlock-123           [-1, 2048, 4, 4]               0\n",
      "AdaptiveAvgPool2d-124           [-1, 2048, 1, 1]               0\n",
      "          Linear-125                   [-1, 10]          20,490\n",
      "     Final_layer-126                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 23,550,474\n",
      "Trainable params: 23,550,474\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 66.64\n",
      "Params size (MB): 89.84\n",
      "Estimated Total Size (MB): 156.49\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_50 = ResNet50(in_channels= 3, layer0=Layer0, bottleneckblock=BottleneckBlock, final_layer=Final_layer, num_classes= 10).to(device)\n",
    "summary(model_50, input_size= (3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "Iteration 0, training loss = 2.5998\n",
      "Validation set accuracy is : 10.80%\n",
      "\n",
      "Iteration 100, training loss = 1.7053\n",
      "Validation set accuracy is : 36.90%\n",
      "\n",
      "Iteration 200, training loss = 1.6747\n",
      "Validation set accuracy is : 42.90%\n",
      "\n",
      "Iteration 300, training loss = 1.5991\n",
      "Validation set accuracy is : 44.40%\n",
      "\n",
      "Iteration 400, training loss = 1.3627\n",
      "Validation set accuracy is : 43.30%\n",
      "\n",
      "Iteration 500, training loss = 1.4050\n",
      "Validation set accuracy is : 49.80%\n",
      "\n",
      "Iteration 600, training loss = 1.2601\n",
      "Validation set accuracy is : 47.40%\n",
      "\n",
      "Iteration 700, training loss = 1.1633\n",
      "Validation set accuracy is : 57.70%\n",
      "\n",
      "Starting epoch 2\n",
      "Iteration 0, training loss = 1.2004\n",
      "Validation set accuracy is : 46.80%\n",
      "\n",
      "Iteration 100, training loss = 0.8140\n",
      "Validation set accuracy is : 65.70%\n",
      "\n",
      "Iteration 200, training loss = 0.9901\n",
      "Validation set accuracy is : 63.90%\n",
      "\n",
      "Iteration 300, training loss = 0.9632\n",
      "Validation set accuracy is : 65.20%\n",
      "\n",
      "Iteration 400, training loss = 0.6865\n",
      "Validation set accuracy is : 66.80%\n",
      "\n",
      "Iteration 500, training loss = 0.8948\n",
      "Validation set accuracy is : 70.50%\n",
      "\n",
      "Iteration 600, training loss = 0.7871\n",
      "Validation set accuracy is : 63.10%\n",
      "\n",
      "Iteration 700, training loss = 0.7002\n",
      "Validation set accuracy is : 67.70%\n",
      "\n",
      "Starting epoch 3\n",
      "Iteration 0, training loss = 0.8223\n",
      "Validation set accuracy is : 68.70%\n",
      "\n",
      "Iteration 100, training loss = 0.7350\n",
      "Validation set accuracy is : 74.60%\n",
      "\n",
      "Iteration 200, training loss = 0.5266\n",
      "Validation set accuracy is : 74.80%\n",
      "\n",
      "Iteration 300, training loss = 0.5378\n",
      "Validation set accuracy is : 74.40%\n",
      "\n",
      "Iteration 400, training loss = 0.6123\n",
      "Validation set accuracy is : 73.40%\n",
      "\n",
      "Iteration 500, training loss = 0.5764\n",
      "Validation set accuracy is : 75.30%\n",
      "\n",
      "Iteration 600, training loss = 0.5070\n",
      "Validation set accuracy is : 75.90%\n",
      "\n",
      "Iteration 700, training loss = 0.5218\n",
      "Validation set accuracy is : 73.50%\n",
      "\n",
      "Starting epoch 4\n",
      "Iteration 0, training loss = 0.4616\n",
      "Validation set accuracy is : 77.80%\n",
      "\n",
      "Iteration 100, training loss = 0.4194\n",
      "Validation set accuracy is : 78.60%\n",
      "\n",
      "Iteration 200, training loss = 0.5641\n",
      "Validation set accuracy is : 79.20%\n",
      "\n",
      "Iteration 300, training loss = 0.3995\n",
      "Validation set accuracy is : 80.00%\n",
      "\n",
      "Iteration 400, training loss = 0.4272\n",
      "Validation set accuracy is : 77.50%\n",
      "\n",
      "Iteration 500, training loss = 0.4203\n",
      "Validation set accuracy is : 79.10%\n",
      "\n",
      "Iteration 600, training loss = 0.5732\n",
      "Validation set accuracy is : 81.10%\n",
      "\n",
      "Iteration 700, training loss = 0.4167\n",
      "Validation set accuracy is : 79.70%\n",
      "\n",
      "Starting epoch 5\n",
      "Iteration 0, training loss = 0.2987\n",
      "Validation set accuracy is : 80.30%\n",
      "\n",
      "Iteration 100, training loss = 0.2408\n",
      "Validation set accuracy is : 82.20%\n",
      "\n",
      "Iteration 200, training loss = 0.2526\n",
      "Validation set accuracy is : 81.80%\n",
      "\n",
      "Iteration 300, training loss = 0.2600\n",
      "Validation set accuracy is : 82.30%\n",
      "\n",
      "Iteration 400, training loss = 0.1930\n",
      "Validation set accuracy is : 82.40%\n",
      "\n",
      "Iteration 500, training loss = 0.1865\n",
      "Validation set accuracy is : 80.80%\n",
      "\n",
      "Iteration 600, training loss = 0.1727\n",
      "Validation set accuracy is : 81.50%\n",
      "\n",
      "Iteration 700, training loss = 0.3143\n",
      "Validation set accuracy is : 81.20%\n",
      "\n",
      "Starting epoch 6\n",
      "Iteration 0, training loss = 0.1436\n",
      "Validation set accuracy is : 82.00%\n",
      "\n",
      "Iteration 100, training loss = 0.1662\n",
      "Validation set accuracy is : 82.90%\n",
      "\n",
      "Iteration 200, training loss = 0.0702\n",
      "Validation set accuracy is : 83.00%\n",
      "\n",
      "Iteration 300, training loss = 0.1874\n",
      "Validation set accuracy is : 82.20%\n",
      "\n",
      "Iteration 400, training loss = 0.1408\n",
      "Validation set accuracy is : 83.00%\n",
      "\n",
      "Iteration 500, training loss = 0.1078\n",
      "Validation set accuracy is : 82.40%\n",
      "\n",
      "Iteration 600, training loss = 0.0797\n",
      "Validation set accuracy is : 82.60%\n",
      "\n",
      "Iteration 700, training loss = 0.1856\n",
      "Validation set accuracy is : 83.00%\n",
      "\n",
      "Starting epoch 7\n",
      "Iteration 0, training loss = 0.0862\n",
      "Validation set accuracy is : 82.80%\n",
      "\n",
      "Iteration 100, training loss = 0.1218\n",
      "Validation set accuracy is : 83.60%\n",
      "\n",
      "Iteration 200, training loss = 0.1122\n",
      "Validation set accuracy is : 83.00%\n",
      "\n",
      "Iteration 300, training loss = 0.0699\n",
      "Validation set accuracy is : 83.00%\n",
      "\n",
      "Iteration 400, training loss = 0.0255\n",
      "Validation set accuracy is : 82.90%\n",
      "\n",
      "Iteration 500, training loss = 0.1351\n",
      "Validation set accuracy is : 82.30%\n",
      "\n",
      "Iteration 600, training loss = 0.1437\n",
      "Validation set accuracy is : 82.20%\n",
      "\n",
      "Iteration 700, training loss = 0.0582\n",
      "Validation set accuracy is : 83.00%\n",
      "\n",
      "Starting epoch 8\n",
      "Iteration 0, training loss = 0.0207\n",
      "Validation set accuracy is : 82.50%\n",
      "\n",
      "Iteration 100, training loss = 0.0998\n",
      "Validation set accuracy is : 82.80%\n",
      "\n",
      "Iteration 200, training loss = 0.0763\n",
      "Validation set accuracy is : 82.80%\n",
      "\n",
      "Iteration 300, training loss = 0.0366\n",
      "Validation set accuracy is : 82.70%\n",
      "\n",
      "Iteration 400, training loss = 0.0613\n",
      "Validation set accuracy is : 82.80%\n",
      "\n",
      "Iteration 500, training loss = 0.0509\n",
      "Validation set accuracy is : 82.70%\n",
      "\n",
      "Iteration 600, training loss = 0.1213\n",
      "Validation set accuracy is : 82.20%\n",
      "\n",
      "Iteration 700, training loss = 0.0783\n",
      "Validation set accuracy is : 82.50%\n",
      "\n",
      "Starting epoch 9\n",
      "Iteration 0, training loss = 0.0314\n",
      "Validation set accuracy is : 82.30%\n",
      "\n",
      "Iteration 100, training loss = 0.0037\n",
      "Validation set accuracy is : 82.30%\n",
      "\n",
      "Iteration 200, training loss = 0.0312\n",
      "Validation set accuracy is : 82.70%\n",
      "\n",
      "Iteration 300, training loss = 0.0097\n",
      "Validation set accuracy is : 82.60%\n",
      "\n",
      "Iteration 400, training loss = 0.1115\n",
      "Validation set accuracy is : 82.50%\n",
      "\n",
      "Iteration 500, training loss = 0.1029\n",
      "Validation set accuracy is : 82.20%\n",
      "\n",
      "Iteration 600, training loss = 0.0722\n",
      "Validation set accuracy is : 82.80%\n",
      "\n",
      "Iteration 700, training loss = 0.0455\n",
      "Validation set accuracy is : 82.60%\n",
      "\n",
      "Starting epoch 10\n",
      "Iteration 0, training loss = 0.0347\n",
      "Validation set accuracy is : 82.90%\n",
      "\n",
      "Iteration 100, training loss = 0.0176\n",
      "Validation set accuracy is : 83.20%\n",
      "\n",
      "Iteration 200, training loss = 0.0104\n",
      "Validation set accuracy is : 82.90%\n",
      "\n",
      "Iteration 300, training loss = 0.0268\n",
      "Validation set accuracy is : 82.70%\n",
      "\n",
      "Iteration 400, training loss = 0.0259\n",
      "Validation set accuracy is : 82.90%\n",
      "\n",
      "Iteration 500, training loss = 0.0645\n",
      "Validation set accuracy is : 82.80%\n",
      "\n",
      "Iteration 600, training loss = 0.0124\n",
      "Validation set accuracy is : 82.80%\n",
      "\n",
      "Iteration 700, training loss = 0.0287\n",
      "Validation set accuracy is : 83.10%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(f'TB/model_50')\n",
    "learning_rate = 1e-3\n",
    "optimizer= optim.Adam(model_50.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.5)  # lr decay every epoch\n",
    "\n",
    "training_loop(model_50, optimizer, epochs=10, decay= True)\n",
    "torch.save(model_50.state_dict(), \"model_50_saved.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary, Comparison and Inferece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading saved models\n",
    "model_18.load_state_dict(torch.load(\"model_18_saved.pth\"))\n",
    "model_34.load_state_dict(torch.load(\"model_34_saved.pth\")) \n",
    "model_50.load_state_dict(torch.load(\"model_50_saved.pth\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resnet 18 test acc: 84.13%\n",
      "Resnet 34 test acc: 84.50%\n",
      "Resnet 50 test acc: 81.14%\n"
     ]
    }
   ],
   "source": [
    "#Comparing models accuracies on test set\n",
    "test_acc_model18 = check_accuracy(loader_test, model_18)\n",
    "test_acc_model34 = check_accuracy(loader_test, model_34)\n",
    "test_acc_model50 = check_accuracy(loader_test, model_50)\n",
    "\n",
    "print(f\"Resnet 18 test acc: {100*test_acc_model18:.2f}%\")\n",
    "print(f\"Resnet 34 test acc: {100*test_acc_model34:.2f}%\")\n",
    "print(f\"Resnet 50 test acc: {100*test_acc_model50:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now after testing the model's we can choose the best one, in this case Resnet34, and use it to sample images from the test set and see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 250x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: deer | Model's prediction label: deer\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO8AAADuCAYAAADRLFAcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAYnUlEQVR4nO3dbVBUV5oH8D+40L7BJYg2UkLCGCs6o5IJEezSTfmCEtfNaoKpJM5sSGLiSEDHkNlZyUadcVKDJZPEmKDOTDKSZELMmh3MqDO+LCKWFpKIuL7CJo4VOyWNIVN0E5AX4ewH1046nINcuNh94P+r6g8+9/a95wKPt/vp088JEkIIEJF2gv09ACLqGSYvkaaYvESaYvISaYrJS6QpJi+Rppi8RJpi8hJpislLpCkmL5Gm/qGvDpyfn4+8vDy4XC4kJCTg9ddfR1JS0k2f19HRgcuXLyMsLAxBQUF9NTyigCWEQENDA2JiYhAc3MX9VfSB7du3i9DQUPGHP/xBnD17VjzzzDMiIiJC1NbW3vS5TqdTAOCDjwH/cDqdXeZKkBDWfzEhOTkZU6ZMwRtvvAHg+t00NjYWy5cvx6pVq7p8rtvtRkREBJxOJ8LDw322NSme41LEv2dy3CpPLt4ljf9pz49NHecBRXwNpkrjU3DM1PHdbrep/SkweTwexMbGor6+HoZhKPez/GVza2srKioqkJOT440FBwcjJSUFZWVlnfZvaWlBS0uL998NDQ0AgPDw8E7JqxpsoyIeroibFRIy1JrjKOLDLfo1fPfnRXq72dtGywtWdXV1aG9vh91u94nb7Xa4XJ3vkbm5uTAMw/uIjY21ekhE/ZLfq805OTlwu93eh9Pp9PeQiLRg+cvmqKgoDBo0CLW1tT7x2tpaREdHd9rfZrPBZrN169iqF69jzQ5S4dEJOdL4B1XrpfFIxXEWmDyvc/4iaXzPHvkVr8V+afxfUzdL4+/ue9bkiNRU76pVvxvVWwXqPcvvvKGhoUhMTERxcbE31tHRgeLiYjgcDqtPRzRg9cnnvNnZ2UhPT8e9996LpKQkbNy4EY2NjXjyySf74nREA1KfJO8jjzyCL7/8EmvWrIHL5cLdd9+NvXv3dipiEVHP9dkMq6ysLGRlZfXV4YkGPL9Xm4moZ/pkhlVveDweGIYBt9t9yycd/EvQSGn8Auqk8SUmj/+hIv6uoiY7Fm3S+DuK46Qr4oWn5L/ixyYpnkA9dlRRjm+S/wlhjuSjku7mAO+8RJpi8hJpislLpCkmL5GmmLxEmuqzz3l19OeDX8o3zFQ8IUj+PdwLKJfGs5VnlleVLyj2bhq7WhoXn61TnoF65pIiXqn85cjDh0rqpfG65IjOh1B9x/U7eOcl0hSTl0hTTF4iTTF5iTTF5CXS1ICsNqu6QRiqqrLKeXl3R2OCuX7TNYr40fS90viyglRTx6dvpPyoQBovLlR911w+7/yF/2yVxsMV7RDr6uTl6aMlUZ1irc0NirH44p2XSFNMXiJNMXmJNMXkJdIUk5dIUwOy2qxa80hV9R2vOpBiQxTmS+MHsEcaf11x+D+zquz1yk75vPPnHxzVp+eNf/hP0njSXPn+lTvlf0VRnYvKAIC2NslfY/vV7gyNd14iXTF5iTTF5CXSFJOXSFNMXiJN9etqs2oO8xvyRfYwRLHU3YvTFQc6IQ9XzZVPkn5/v7za/OfAap19S4xI/Kk0/vcTmyw5/v2L5V1FlqTLu20vmhsjjb+05bw0XlUlP+/p04oNbfJuKU1NnedOX2tVfR7ii3deIk0xeYk0xeQl0hSTl0hTTF4iTfWLVQIV9T38h6JwOSlZHs9SxBXTUrUnr3+qekdcd1QxAXx6zO2KZ6g6H8uFxclL+8tXyLte/+TpB6XxOMPUaZXqFIXfp9bLq9AXyv8ijX/lli8TaIR0/oij/VozLhz7NVcJJOqvmLxEmmLyEmmKyUukKSYvkaa0mtv8kaLyt/VNeXxZhjyepCinnlGc9y5FfLQiHmhU16WqpLapJoUDOC1fABHKqrIhbzfy5OLF0vic+f8kjT82P1E9KAuoVv3b+maBNH5o/9+k8YYa1Wcfcm1G588yRLu8J/R38c5LpCkmL5GmmLxEmmLyEmmKyUukqYCtNm89DgwZ5hv7m2Je7Ysr5HHV9NavTI5FVeVepui8oaLqj2DyMMoOIdWKycoXFJVUt2J/WSvhG4aanejtlldfFzy8SBoPkcz17YpqfvZf9n8ujVdVyX8Yrjr53OOJk+6RxrMnyedg/zLnJWl8dnKSNB4X1/kzi9aWJrz36VvS/b+Nd14iTTF5iTTF5CXSFJOXSFNMXiJNma42Hz58GHl5eaioqEBNTQ2KioqwcOFC73YhBNauXYvf//73qK+vx7Rp07BlyxaMGzfO1HlixwBDw3xjCxSdLjyKY5i9uK46SMj8QlHF/cVYedxsVVnVg6JSsaFGUY13K8rTX9XIm6i461TrJQJ1qpMoVkaEYmXEAyUl0nhbk3yFvLfell/E2Dh5FTdpurwanDxzljR+pOSUNL7h5Xek8S9OvCyNI+Rhabh4R6Z8/14wfedtbGxEQkIC8vPzpds3bNiATZs2YevWrSgvL8ewYcOQmpqK5ubmXg+WiL5h+s47b948zJs3T7pNCIGNGzfixRdfxIIFCwAA77zzDux2O3bu3IlHH320d6MlIi9L3/NevHgRLpcLKSkp3phhGEhOTkZZWZn0OS0tLfB4PD4PIro5S5PX5XIBAOx2u0/cbrd7t31Xbm4uDMPwPmJjY60cElG/5fdqc05ODtxut/fhdDr9PSQiLVg6tzk6OhoAUFtbi9Gjv5mzWVtbi7vvvlv6HJvNBpvN1ik+NRoI+07LWtWc3hGKuKq6q/rv4ZJioqxbMdf3kqLq+5PT8vhvFyqOrxiPqruDaoU6Z428A0ONYqB1iqpyXY3ixAC+qlH89OIUk54VP6N3trwvjYdIOksAwJIV/y6Nz5g7VRo/US6f27w69QH5gNqOyOMmDU5eII03H9lhyfG/zdI7b3x8PKKjo1FcXOyNeTwelJeXw+FwWHkqogHP9J3366+/xmeffeb998WLF3Hy5ElERkYiLi4OK1euxEsvvYRx48YhPj4eq1evRkxMjM9nwUTUe6aT9/jx45g585vFo7Ozry9DkZ6ejoKCAvz85z9HY2Mjli5divr6ekyfPh179+7F4MGDrRs1EZlP3hkzZqCr5Y2CgoKwbt06rFsnX5mciKzh92ozEfVMwHbSkDG78Fu1Il6lqB43KarNHkU5WFVtLn57tzQ+1P3P0vicmdIwPj6hOu+X8riiZYbrkjxeo6gcN9R1sbJfjWJbm6qnhVyDWz6T/IVVL0rjbsXx508YqTiDvDNGXwtRNL3ui8nBvPMSaYrJS6QpJi+Rppi8RJpi8hJpKmCrzW3o3JNX1U5YtQpejWrSsMl+xaqF36qPfCbfUCOvdG58JkcaP53xmHw8igH9TVE9dquqx6oKsbIrhrqThrqKq3jO6Kel4aUrlkjjv/7ZvV2c2x/kqxwC8j+KqDb5ZxwNFo3m23jnJdIUk5dIU0xeIk0xeYk0xeQl0lSQ6OorQn7g8XhgGAYKa9wYGu7bSkNVbVZ1ulBNt1XFqxUdMI7sl88lri6X9x5uP3FUcWLFZGVVx+jRk+TxJkUZ3W2yEqzsDN2TecGqviVdLDnoF51X5btO9TNS7a9i7jgnzn/aKfb11x7cNyUGbrcb4d/JgW/jnZdIU0xeIk0xeYk0xeQl0hSTl0hTATu3+exxYPAw39hQxep7qjnJqqqyU1FkPVJyWb5/lbwM3V6lmFXdVi6PQ1HOVlVkVZOqlesZqrpZqCqg90ijYePTFfsDDVVvK7b4p3OFur+KamJ7V/O2rdhfTgj535aMx9Perf145yXSFJOXSFNMXiJNMXmJNMXkJdJUwFabP3zrvzEoxLfcPDM9VbpviKL4eklRKPy4/Lw0XqfoUNF8QdEB2q2qHquqxGbn+VpT6QyLk3ez+N74H0rj/7P/37o4mqqzhL+qzaqqsn88tPj5W3Yu3nmJNMXkJdIUk5dIU0xeIk0xeYk0xeQl0lTAtsGRuXdF55YhANAWIt/fVaNoTq5oF9OsakJ+olIeh+oLCKp2N33L8fSfpPGyNzMVz7Dmo6jrzH5Zon+yIp1u5ADb4BD1U0xeIk0xeYk0xeQl0hSTl0hTAfvFBJnjO7ZK44PHJ0njbYpKZ3udYjK76gsIkFet1fG+lZC+VxpX13WtrCqr+KeqvPT530jjv3v5V4pnWPNFhkhVQ3yTmiQ/NllMhndeIk0xeYk0xeQl0hSTl0hTTF4iTWlVbUbNy9Jwc9sq+f4himUn3YqKY5PZpTD7uAXLpFx5eOZcafyPT/Tf/4sd8xdL4wdKdiie0be/m98WbJTGf/LsT6Xxujr5fPqk5BmdYs3NV7s1hv772ybq55i8RJpi8hJpislLpClTyZubm4spU6YgLCwMo0aNwsKFC1Fd7TulsLm5GZmZmRgxYgSGDx+OtLQ01NbWWjpoIjLZSeP+++/Ho48+iilTpuDatWt44YUXcObMGZw7dw7Dhl1vkJ6RkYE9e/agoKAAhmEgKysLwcHBOHr0aLfO0VUnDTX5UpXqBuFml3+0qom6wtAV8rgRJY+PVlTRT/zMmvGQ5dbm5kvjTz2d0SnW0ODBxO9F3LSThqmPivbu9Z0QX1BQgFGjRqGiogL33Xcf3G433nrrLRQWFmLWrFkAgG3btmHChAk4duwYpk6dauZ0RNSFXr3ndf//56WRkZEAgIqKCrS1tSElJcW7z/jx4xEXF4eysjLpMVpaWuDxeHweRHRzPU7ejo4OrFy5EtOmTcPEiRMBAC6XC6GhoYiIiPDZ1263w+VySY+Tm5sLwzC8j9jY2J4OiWhA6XHyZmZm4syZM9i+fXuvBpCTkwO32+19OJ3OXh2PaKDo0fTIrKws7N69G4cPH8aYMWO88ejoaLS2tqK+vt7n7ltbW4vo6GjpsWw2G2w2W0+GQTSgmUpeIQSWL1+OoqIiHDp0CPHx8T7bExMTERISguLiYqSlpQEAqqurcenSJTgcDutG3YmqT7LZ7g6qarNFVWXMVxxecd6mI/K4qr+0H7353mFpfMnifzR1nNgJs6TxL6pKTI+pL4VFxUnj/7Vb3jt7TnKiNC77Cx0WGtStMZhK3szMTBQWFuKjjz5CWFiY932sYRgYMmQIDMPAkiVLkJ2djcjISISHh2P58uVwOBysNBNZzFTybtmyBQAwY8YMn/i2bdvwxBNPAABeffVVBAcHIy0tDS0tLUhNTcXmzZstGSwRfcP0y+abGTx4MPLz85GfL/9QmoiswbnNRJpi8hJpSq9OGqadVsQVc4MtqyonK+Kq8ag6dcjHGTl9tTT+9yM5XY6qu+6dma7c9snBAkvO8dLL8uMEWlX5x0/Lu7T8Yt0vpfG40aHSeF90teadl0hTTF4iTTF5iTTF5CXSFJOXSFP9vNqsYlVVWdXxo9zkceQ9iYFCadSqqrKJJipeB44clMbnznpI/oS2Pu5tbdpYabRw9wfSeNI98i4tISHy+ceqFf6MkJuPzHvsbu7HOy+Rppi8RJpi8hJpislLpCkmL5GmBmi12SpWVVLlVWWzzFaP70qUd3f43xOqziT6+PGKddJ49vPZ0vjEuGHSuGpBySizrcX7AO+8RJpi8hJpislLpCkmL5GmmLxEmmK1OYAlJM+VxmfOlHfqCArqXr9fHdnHTpfG331vmzT+w3vulMaHmphjDARGVVmFd14iTTF5iTTF5CXSFJOXSFNMXiJNBYmetFPoQx6PB4YRwCU+H1HS6PnL56TxQyU7pfGMHy21akAakZd9NxXslcYfe1i+eqChasFt6qyB5UYOuN1uhIeHK/fjnZdIU0xeIk0xeYk0xeQl0hSTl0hTnNvcK3XS6ISYUbd4HIEr8/mN0vhzqzKk8ago+Sp7qqKyDtXjvsI7L5GmmLxEmmLyEmmKyUukKSYvkaZYbSZTHHOflsY3/uaX0vgPJ8VI4wO5SmwV3nmJNMXkJdIUk5dIU0xeIk0xeYk0xWrzADY4St7/+d33fqd8zpy5k6VxXXqf9Ce88xJpislLpCkmL5GmmLxEmjKVvFu2bMHkyZMRHh6O8PBwOBwO/PWvf/Vub25uRmZmJkaMGIHhw4cjLS0NtbW1lg+aiEz2bd61axcGDRqEcePGQQiBt99+G3l5eaisrMQPfvADZGRkYM+ePSgoKIBhGMjKykJwcDCOHj3a7QHp1bc50IyVRre890dp/LHFU6Vx/vT9q7t9m3vddD0yMhJ5eXlYtGgRRo4cicLCQixatAgAUFVVhQkTJqCsrAxTp8r/UFQDp55g8vYHfd50vb29Hdu3b0djYyMcDgcqKirQ1taGlJQU7z7jx49HXFwcysrKlMdpaWmBx+PxeRDRzZlO3tOnT2P48OGw2WxYtmwZioqK8P3vfx8ulwuhoaGIiIjw2d9ut8PlcimPl5ubC8MwvI/Y2FjTF0E0EJlO3rvuugsnT55EeXk5MjIykJ6ejnPn5GvzdEdOTg7cbrf34XQ6e3wsooHE9PTI0NBQ3HnnnQCAxMREfPLJJ3jttdfwyCOPoLW1FfX19T5339raWkRHRyuPZ7PZYLPZzI+caIDr9dzmjo4OtLS0IDExESEhISguLkZaWhoAoLq6GpcuXYLD4ej1QAem0dLorzbnS+OPPzxfGh86VN4LmYUpvZlK3pycHMybNw9xcXFoaGhAYWEhDh06hH379sEwDCxZsgTZ2dmIjIxEeHg4li9fDofD0e1KMxF1n6nkvXLlCh5//HHU1NTAMAxMnjwZ+/btw5w5cwAAr776KoKDg5GWloaWlhakpqZi8+bNfTJwooGOi2sHtL592RxlcmFqujW4uDZRPxdwX8YPsBcCftYhjTZfbZLGGxrkE1zar8nvvKHXejYq6ls3JirdLBcC7mXzF198wYkaRACcTifGjBmj3B5wydvR0YHLly8jLCwMDQ0NiI2NhdPp7PK1f3/i8XgG1DXzejsTQqChoQExMTEIDla/sw24l83BwcHe/22CgoIAwPsVxIFkoF0zr9dXd4q2LFgRaYrJS6SpgE5em82GtWvXDqi5zwPtmnm9PRdwBSsi6p6AvvMSkRqTl0hTTF4iTTF5iTTF5CXSVEAnb35+Pu644w4MHjwYycnJ+Pjjj/09JEscPnwYDzzwAGJiYhAUFISdO3f6bBdCYM2aNRg9ejSGDBmClJQUfPrpp/4ZrAVyc3MxZcoUhIWFYdSoUVi4cCGqq6t99ulPDftv1eIEAZu8H3zwAbKzs7F27VqcOHECCQkJSE1NxZUrV/w9tF5rbGxEQkIC8vPl38vdsGEDNm3ahK1bt6K8vBzDhg1Damoqmpubb/FIrVFaWorMzEwcO3YMBw4cQFtbG+bOnYvGxkbvPs899xx27dqFHTt2oLS0FJcvX8ZDDz3kx1H33JgxY7B+/XpUVFTg+PHjmDVrFhYsWICzZ88CsPBaRYBKSkoSmZmZ3n+3t7eLmJgYkZub68dRWQ+AKCoq8v67o6NDREdHi7y8PG+svr5e2Gw28f777/thhNa7cuWKACBKS0uFENevLyQkROzYscO7z/nz5wUAUVZW5q9hWuq2224Tb775pqXXGpB33tbWVlRUVPg0cA8ODkZKSkqXDdz7g4sXL8Llcvlcu2EYSE5O7jfX7na7AVxfbQNAjxv268CqxQlkAu5bRQBQV1eH9vZ22O12n7jdbkdVVZWfRnVr3GhQL7v2rprX66KjowMrV67EtGnTMHHiRADoccP+QHb69Gk4HA40Nzdj+PDh3sUJTp48adm1BmTyUv+VmZmJM2fO4MiRI/4eSp+6sTiB2+3Ghx9+iPT0dJSWllp6joB82RwVFYVBgwZ1qsDdrIF7f3Dj+vrjtWdlZWH37t0oKSnx6RARHR3tbdj/bTpf843FCRITE5Gbm4uEhAS89tprll5rQCZvaGgoEhMTUVxc7I11dHSguLi43zdwj4+PR3R0tM+1ezwelJeXa3vtQghkZWWhqKgIBw8eRHx8vM/2bzfsv6G/NeyXLU5wQ4+v1eKimmW2b98ubDabKCgoEOfOnRNLly4VERERwuVy+XtovdbQ0CAqKytFZWWlACBeeeUVUVlZKT7//HMhhBDr168XERER4qOPPhKnTp0SCxYsEPHx8eLq1at+HnnPZGRkCMMwxKFDh0RNTY330dTU5N1n2bJlIi4uThw8eFAcP35cOBwO4XA4/Djqnlu1apUoLS0VFy9eFKdOnRKrVq0SQUFBYv/+/UII6641YJNXCCFef/11ERcXJ0JDQ0VSUpI4duyYv4dkiZKSEgGg0yM9PV0Icf3jotWrVwu73S5sNpuYPXu2qK6u9u+ge0F2rQDEtm3bvPtcvXpVPPvss+K2224TQ4cOFQ8++KCoqanx36B74amnnhK33367CA0NFSNHjhSzZ8/2Jq4Q1l0rv89LpKmAfM9LRDfH5CXSFJOXSFNMXiJNMXmJNMXkJdIUk5dIU0xeIk0xeYk0xeQl0hSTl0hT/weCXfG002+2uwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 250x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: automobile | Model's prediction label: airplane\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 250x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: cat | Model's prediction label: cat\n"
     ]
    }
   ],
   "source": [
    "#Random sampling from test set\n",
    "def sample_test(model, num_samples=1):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(num_samples):\n",
    "            x , y = cifar10_test[floor(random.random()*len(cifar10_test))]\n",
    "            true_label = labels_dic[y]\n",
    "            x = x.unsqueeze(0).to(device)\n",
    "            logits = model(x)\n",
    "            _, y_pred = logits.max(1)\n",
    "            pred_label = labels_dic[y_pred.item()]\n",
    "            x = x.squeeze().cpu().permute(1,2,0).clamp(0,1)\n",
    "            plt.figure(figsize=(2.5,2.5))\n",
    "            plt.imshow(x)\n",
    "            plt.show()\n",
    "            print(f\"True label: {true_label} | Model's prediction label: {pred_label}\")\n",
    "\n",
    "sample_test(model_34, num_samples=3)            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
